{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  4.254954668230921\n",
      "Test RMSE: 6.023416146614772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Train RMSE: \", np.sqrt(mean_squared_error(lr.predict(X_train), y_train)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(lr.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, X_train, X_test, y_train, y_test):\n",
    "    lr = model\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"Train r2\", lr.score(X_train, y_train))\n",
    "    print(\"Test r2\", lr.score(X_test, y_test))\n",
    "    print(\"Train RMSE: \", np.sqrt(mean_squared_error(lr.predict(X_train), y_train)))\n",
    "    print(\"Test RMSE:\", np.sqrt(mean_squared_error(lr.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model_test() missing 2 required positional arguments: 'y_train' and 'y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-204d69f22376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: model_test() missing 2 required positional arguments: 'y_train' and 'y_test'"
     ]
    }
   ],
   "source": [
    "model_test(LinearRegression(), X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 0.7818224053670757\n",
      "Test r2 0.6062839111363423\n",
      "Train RMSE:  4.255160545827858\n",
      "Test RMSE: 5.909093700780388\n"
     ]
    }
   ],
   "source": [
    "model_test(Ridge(), X_train, X_test,   y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 0.7818432926158021\n",
      "Test r2 0.6063972763740455\n",
      "Train RMSE:  4.2549568568923775\n",
      "Test RMSE: 5.908242917615769\n"
     ]
    }
   ],
   "source": [
    "model_test(Ridge(alpha=0.1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 0.7805456511517963\n",
      "Test r2 0.6041937050970777\n",
      "Train RMSE:  4.267592778607969\n",
      "Test RMSE: 5.924758381694348\n"
     ]
    }
   ],
   "source": [
    "model_test(Ridge(alpha = 10), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidin(alph):\n",
    "    model_test(Ridge(alpha = alph), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 0.7705493363358535\n",
      "Test r2 0.5933280825665161\n",
      "Train RMSE:  4.363706523702593\n",
      "Test RMSE: 6.005530642650671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.slidin>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(slidin, alph = (0.001, 100, .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_default = Ridge().fit(X_train, y_train).coef_\n",
    "ridge_small = Ridge(alpha = 0.1).fit(X_train, y_train).coef_\n",
    "ridge_large = Ridge(alpha = 100).fit(X_train, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(ridge_default, 's', label = 'alpha = 1.0')\n",
    "plt.plot(ridge_small, 'o', label = 'alpha = 0.1')\n",
    "plt.plot(ridge_large, 'v', label = 'alpha = 100')\n",
    "plt.axhline(color = 'black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(Lasso())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(ElasticNet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "Examine the plots of coefficients for three different values of alpha.  Compare and contrast what we see with the four models (`LinearRegression`, `Ridge`, `Lasso`, `ElasticNet`) in terms of the values of coefficients across alpha values, and the values from model to model.\n",
    "\n",
    "If you have time, find the ideal value for our regularization parameter using the `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification and Regularization\n",
    "\n",
    "Here, we are focused on `LogisticRegression`, and the use of different regularization parameters and values for these parameters.  The aim is to draw connections between what happens with Regularization across our least squares strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.coef_.T, 'o', label = 'Logistic Default')\n",
    "plt.axhline(color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_small = LogisticRegression(C = 0.1)\n",
    "clf_small.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.coef_.T, 'o', label = 'Logistic Default')\n",
    "plt.plot(clf_small.coef_.T, '^', label = 'C = 0.1')\n",
    "plt.axhline(color = 'black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_big = LogisticRegression(C = 100)\n",
    "clf_big.fit(X_train, y_train)\n",
    "plt.plot(clf.coef_.T, 'o', label = 'Logistic Default')\n",
    "plt.plot(clf_small.coef_.T, '^', label = 'C = 0.1')\n",
    "plt.plot(clf_big.coef_.T, 'x', label = 'C = 100')\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation = 90)\n",
    "plt.axhline(color = 'black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_l1 = LogisticRegression(C = 1.0, penalty='l1')\n",
    "clf_l1_small = LogisticRegression(C = 0.1, penalty='l1')\n",
    "clf_l1_large = LogisticRegression(C = 100, penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_l1.fit(X_train, y_train)\n",
    "clf_l1_small.fit(X_train, y_train)\n",
    "clf_l1_large.fit(X_train, y_train)\n",
    "\n",
    "plt.plot(clf_l1.coef_.T, 'o', alpha = 0.8, label = 'Default')\n",
    "plt.plot(clf_l1_small.coef_.T, '^', alpha = 0.6, label = 'C = 0.1')\n",
    "plt.plot(clf_l1_large.coef_.T, 'v', alpha = 0.3, label = 'C = 100')\n",
    "plt.axhline(color = 'black')\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation = 90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "- We use regularization in both classification and regression\n",
    "- Depending on the task, we want either `L1` or `L2` penalties\n",
    "- We can grid search to find ideal `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
